{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, MaxPooling2D, UpSampling2D, Input, Rescaling, BatchNormalization\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7909b",
   "metadata": {},
   "source": [
    "# Anemia prediction (Classification & Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"classification\"\n",
    "#mode = \"regression\"\n",
    "binary = True\n",
    "threshold = [7.0, 10.0, 12.5]\n",
    "threshold_name = [\"severely anemic\", \"moderately anemic\", \"mildly anemic\", \"non-anemic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209f854",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = os.path.join(\"D:\", \"OneDrive_1_5-26-2022\", \"PredictingAnemia_DATA_2022-06-05_0643.csv\")\n",
    "label = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[\"hgb\"] = pd.to_numeric(label[\"hgb\"], errors=\"coerce\")\n",
    "drop_index = np.where(pd.isnull(label[\"hgb\"]))\n",
    "print(\"drop (contains string or null): \", drop_index[0])\n",
    "label = label.drop(drop_index[0])\n",
    "print(\"mean:\", label[\"hgb\"].mean(), \"std:\", label[\"hgb\"].std())\n",
    "print(\"anemia mean: \", label[\"hgb\"][label[\"hgb\"] < 12.5].mean())\n",
    "print(\"non-anemia mean: \", label[\"hgb\"][label[\"hgb\"] >= 12.5].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_label(label_i, threshold):\n",
    "    label = -1\n",
    "    for i, threshold_i in enumerate(threshold):\n",
    "        if label_i < threshold_i:\n",
    "            label = i\n",
    "            break\n",
    "    if label == -1:\n",
    "        label = len(threshold)\n",
    "    \n",
    "    #print(label, label_i)\n",
    "    \n",
    "    return label\n",
    "\n",
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        y = (label[\"hgb\"] < 12.5).astype(int)\n",
    "    else:\n",
    "        y = np.array([multi_class_label(label_i, threshold) for label_i in label[\"hgb\"]], dtype=np.uint8)\n",
    "        y = pd.Series(data=y, index=label[\"hgb\"].index)\n",
    "elif mode == \"regression\":\n",
    "    y = label[\"hgb\"]\n",
    "print(y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc324d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_available = [] \n",
    "\n",
    "for folder in os.listdir(\"./detected eyes images\"):\n",
    "    if int(folder)-1 in y.index:\n",
    "        y_available.append(int(folder))\n",
    "        \n",
    "print(\"not available id: \")\n",
    "not_available_id = []\n",
    "for i in range(1, 693):\n",
    "    if i not in y_available:\n",
    "        not_available_id.append(i)\n",
    "print(not_available_id)\n",
    "print(\"num: \", len(not_available_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b3320",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = []\n",
    "y_img = []\n",
    "y_id = []\n",
    "\n",
    "for id in y_available:\n",
    "    for image in os.listdir(os.path.join(\"./detected eyes images\", str(id))):\n",
    "        #print(id, image)\n",
    "        img = cv2.imread(os.path.join(\"./detected eyes images\", str(id), image))\n",
    "        #print(img.shape)\n",
    "        x_img.append(tf.image.resize(img, (224, 224)))\n",
    "        y_img.append(y[id-1])\n",
    "        y_id.append(id)\n",
    "        \n",
    "x_img = np.array(x_img, dtype=np.uint8)\n",
    "y_img = np.array(y_img)\n",
    "print(x_img.shape, y_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552220fd",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce77c67",
   "metadata": {},
   "source": [
    "### Autoenconder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d594fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(array):\n",
    "    \"\"\"\n",
    "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
    "    \"\"\"\n",
    "\n",
    "    array = array.astype(\"float32\") / 255.0\n",
    "    array = np.reshape(array, (len(array), 224, 224, 3))\n",
    "    return array.astype(np.float32)\n",
    "\n",
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "def display(array1, array2):\n",
    "    \"\"\"\n",
    "    Displays ten random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    \n",
    "    images1 = np.zeros_like(array1[indices, :])\n",
    "    images2 = np.zeros_like(array2[indices, :])\n",
    "    images1[:, :, :, 0] = array1[indices, :, :, 2]\n",
    "    images1[:, :, :, 1] = array1[indices, :, :, 1]\n",
    "    images1[:, :, :, 2] = array1[indices, :, :, 0]\n",
    "    images2[:, :, :, 0] = array2[indices, :, :, 2]\n",
    "    images2[:, :, :, 1] = array2[indices, :, :, 1]\n",
    "    images2[:, :, :, 2] = array2[indices, :, :, 0]\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(image1)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(image2)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "x_img_preprocess = preprocess(x_img)\n",
    "x_img_noise = noise(x_img_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16(tf.keras.Model):\n",
    "    def __init__(self, pretrained = True):\n",
    "        super(Vgg16, self).__init__()\n",
    "        self.vggnet = tf.keras.applications.VGG16(include_top=False, weights=None)\n",
    "        #features = list(self.vggnet.features)\n",
    "        #self.layers = tf.keras.Sequential(features).eval() \n",
    "        \n",
    "    def call(self, x):\n",
    "        results = []\n",
    "        for ii,model in enumerate(self.vggnet.layers):\n",
    "            x = model(x)\n",
    "            if ii in [2,5,9,13,17]:\n",
    "                results.append(x) #(64,256,256),(128,128,128),(256,64,64),(512,32,32),(512,16,16)\n",
    "        return results\n",
    "\n",
    "vgg_model = Vgg16()\n",
    "vgg_model.build(input_shape=(None, 224, 224, 3))\n",
    "vgg_model.summary()\n",
    "\n",
    "class DeConv2d(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding, dilation):\n",
    "        super().__init__()\n",
    "        self.up = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='nearest')\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=out_channel, kernel_size=kernel_size, strides=stride, padding=padding, dilation_rate=dilation)\n",
    "    \n",
    "    def call(self, x):\n",
    "        output = self.up(x)\n",
    "        output = self.conv(output)\n",
    "        return output\n",
    "\n",
    "class UNet(tf.keras.Model):\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        #####################################\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.deconv1 = DeConv2d(512, 512, kernel_size=3, stride=1, padding=\"same\", dilation=1)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.deconv2 = DeConv2d(1024, 256, kernel_size=3, stride=1, padding=\"same\", dilation=1)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.deconv3 = DeConv2d(512, 128, kernel_size=3, stride=1, padding=\"same\", dilation=1)\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.deconv4 = DeConv2d(256, 64, kernel_size=3, stride=1, padding=\"same\", dilation=1)\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.classifier = tf.keras.layers.Conv2D(n_class, kernel_size=1, activation=\"sigmoid\")\n",
    "        #####################################\n",
    "    \n",
    "    def call(self, x):\n",
    "        #####################################\n",
    "        pre_output = self.pretrained_net(x)\n",
    "        output = self.bn1(self.relu(self.deconv1(pre_output[4]))) #(512,32,32)\n",
    "        output = self.bn2(self.relu(self.deconv2(tf.concat([output, pre_output[3]], axis=-1)))) #(256,64,64)\n",
    "        output = self.bn3(self.relu(self.deconv3(tf.concat([output, pre_output[2]], axis=-1)))) #(128,128,128)\n",
    "        output = self.bn4(self.relu(self.deconv4(tf.concat([output, pre_output[1]], axis=-1)))) #(64,256,256)\n",
    "        output = self.classifier(tf.concat([output, pre_output[0]], axis=-1))\n",
    "        return output\n",
    "        #####################################\n",
    "        \n",
    "seg_model = UNet(pretrained_net=vgg_model, n_class=3)\n",
    "seg_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "seg_model.build(input_shape=(None, 224, 224, 3))\n",
    "seg_model.summary()\n",
    "\n",
    "seg_model.fit(\n",
    "    x=x_img_preprocess,\n",
    "    y=x_img_preprocess,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "x_img_denoise = seg_model.predict(x_img_preprocess, batch_size=16)\n",
    "display(x_img_preprocess, x_img_noise)\n",
    "display(x_img_preprocess, x_img_denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471eacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(224, 224, 3))\n",
    "# Encoder\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# Decoder\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(inputs, x)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.fit(\n",
    "    x=x_img_preprocess,\n",
    "    y=x_img_preprocess,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "x_img_denoise = autoencoder.predict(x_img_preprocess, batch_size=16)\n",
    "display(x_img_preprocess, x_img_noise)\n",
    "display(x_img_preprocess, x_img_denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0603205",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = np.array(x_img_denoise * 255.0, copy=True, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded10293",
   "metadata": {},
   "source": [
    "### Changing the contrast and brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2964c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookUpTable = np.empty((1,256), np.uint8)\n",
    "gamma = 1.3\n",
    "for i in range(256):\n",
    "    lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "\n",
    "def adjust_brightness(img, lookUpTable, alpha=1.3, beta=40):\n",
    "    new_image = np.zeros(img.shape, img.dtype)\n",
    "    \n",
    "    #for y in range(img.shape[0]):\n",
    "    #    for x in range(img.shape[1]):\n",
    "    #        for c in range(img.shape[2]):\n",
    "    #            new_image[y,x,c] = np.clip(alpha*img[y,x,c] + beta, 0, 255)\n",
    "\n",
    "    new_image = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "                \n",
    "    res = cv2.LUT(new_image, lookUpTable)\n",
    "                \n",
    "    return res\n",
    "\n",
    "# x_brightness = np.array([adjust_brightness(xi, lookUpTable) for xi in x_img], dtype=np.uint8)\n",
    "# print(x_brightness.shape)\n",
    "\n",
    "# x_preprocessed = np.array(x_brightness, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2141124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = x_img[10]\n",
    "# result = x_brightness[10]\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "# cv2.imshow('result', result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5012f0",
   "metadata": {},
   "source": [
    "### Clustering filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_filter(img, n_clusters=5):\n",
    "    original_shape = img.shape\n",
    "    img = img.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(img)\n",
    "\n",
    "    labels=kmeans.labels_\n",
    "    #print(labels)\n",
    "    labels=list(labels)\n",
    "\n",
    "    centroid=kmeans.cluster_centers_\n",
    "    #print(centroid)\n",
    "\n",
    "    percent=[]\n",
    "    for i in range(len(centroid)):\n",
    "      j=labels.count(i)\n",
    "      j=j/(len(labels))\n",
    "      percent.append(j)\n",
    "    #print(percent)\n",
    "\n",
    "    # bgr to rgb\n",
    "    #plt.pie(percent,colors=np.array(centroid[:, [2, 1, 0]]/255),labels=np.arange(len(centroid)))\n",
    "    #plt.show()\n",
    "\n",
    "    sorted_percent = sorted(percent)\n",
    "    remove_index = [percent_i in [sorted_percent[0], sorted_percent[1]] for percent_i in percent]\n",
    "    #print(remove_index)\n",
    "\n",
    "    result = np.array(img, copy=True)\n",
    "    for i, remove in enumerate(remove_index):\n",
    "        if remove:\n",
    "            result[labels==np.array(i)] = centroid[i]\n",
    "    result = result.reshape(original_shape)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# x_cluster = np.array([clustering_filter(xi) for xi in x_img], dtype=np.uint8)\n",
    "# print(x_cluster.shape)\n",
    "\n",
    "# x_preprocessed = np.array(x_cluster, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = x_img[321]\n",
    "# result = x_cluster[321]\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "# cv2.imshow('result', result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9272ec",
   "metadata": {},
   "source": [
    "### HSV filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_sum = []\n",
    "\n",
    "def hsv_filter(img, init_value=100, end_value=0, average_value=20000, adaptive=False):\n",
    "    mask_value = 0\n",
    "    sv_value = init_value\n",
    "    \n",
    "    if adaptive:\n",
    "        while mask_value <= average_value and sv_value >= end_value:\n",
    "            # Threshold of blue in HSV space\n",
    "            lower_red = np.array([0,sv_value,sv_value])\n",
    "            upper_red = np.array([10,255,255])\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            # preparing the mask to overlay\n",
    "            mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "            mask_value = np.sum(mask/255)\n",
    "            sv_value -= 1\n",
    "    else:\n",
    "        lower_red = np.array([0,sv_value,sv_value])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        # preparing the mask to overlay\n",
    "        mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask_value = np.sum(mask/255)\n",
    "        \n",
    "    dummy_sum.append(mask_value)\n",
    "\n",
    "\n",
    "    # The black region in the mask has the value of 0,\n",
    "    # so when multiplied with original image removes all non-blue regions\n",
    "    result = cv2.bitwise_and(img, img, mask = mask)\n",
    "    \n",
    "    return result\n",
    "\n",
    "x_hsv = np.array([hsv_filter(xi) for xi in x_img], dtype=np.uint8)\n",
    "print(x_hsv.shape)\n",
    "\n",
    "print(np.mean(np.array(dummy_sum), axis=0))\n",
    "\n",
    "x_preprocessed = np.array(x_hsv, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = x_img[60]\n",
    "# result = x_hsv[60]\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "# cv2.imshow('result', result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ac2cb",
   "metadata": {},
   "source": [
    "### Histrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c98dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue, Green, Red and A (Transparency)\n",
    "def red_histogram(img):\n",
    "    return np.histogram(img[:, :, 2].flatten(), range(257))[0]\n",
    "\n",
    "x_hist = np.array([red_histogram(xi) for xi in x_preprocessed])\n",
    "print(x_hist.shape)\n",
    "\n",
    "x_final = x_hist\n",
    "y_final = y_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380753a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(256)[1:] - 0.5, x_hist[0][1:], width=1, edgecolor='none')\n",
    "plt.xlim([-0.5, 255.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca45762",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1458a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by id\n",
    "x_train, y_train = x_final[[i > 80 for i in y_id]], y_final[[i > 80 for i in y_id]]\n",
    "x_test, y_test = x_final[[i <= 80 for i in y_id]], y_final[[i <= 80 for i in y_id]]\n",
    "\n",
    "#x_train, y_train = x_final[[i < 620 for i in y_id]], y_final[[i < 620 for i in y_id]]\n",
    "#x_test, y_test = x_final[[i >= 620 for i in y_id]], y_final[[i >= 620 for i in y_id]]\n",
    "\n",
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        print(\"train: (0)\", np.sum(y_train==0), \"(1)\", np.sum(y_train==1))\n",
    "        print(\"test: (0)\", np.sum(y_test==0), \"(1)\", np.sum(y_test==1))\n",
    "    else:\n",
    "        for i in range(len(threshold)+1):\n",
    "            print(i)\n",
    "            print(\"train:\", np.sum(y_train==i), \" test:\", np.sum(y_test==i))\n",
    "elif mode == \"regression\":\n",
    "    print(np.mean(y_train))\n",
    "    print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2364401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "# scaler = RobustScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be455b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train==0].mean(axis=0)[1:], label='non-anemia')\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train==1].mean(axis=0)[1:], label='anemia')\n",
    "    else:\n",
    "        for i in range(len(threshold)+1):\n",
    "            plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train==i].mean(axis=0)[1:], label=threshold_name[i])\n",
    "elif mode == \"regression\":\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train>=12.5].mean(axis=0)[1:], label='non-anemia')\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train<12.5].mean(axis=0)[1:], label='anemia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8507a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test==0].mean(axis=0)[1:], label='non-anemia')\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test==1].mean(axis=0)[1:], label='anemia')\n",
    "    else:\n",
    "        for i in range(len(threshold)+1):\n",
    "            plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test==i].mean(axis=0)[1:], label=threshold_name[i])\n",
    "elif mode == \"regression\":\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test>=12.5].mean(axis=0)[1:], label='non-anemia')\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test<12.5].mean(axis=0)[1:], label='anemia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ceb83",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860501cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, y_hat, mode, binary):\n",
    "    if mode == \"classification\":\n",
    "        if binary:\n",
    "            average = \"binary\"\n",
    "            multi_class = \"raise\"\n",
    "            display_labels = [\"non-anemia\", \"anemia\"]\n",
    "        else:\n",
    "            average = \"macro\"\n",
    "            multi_class = \"ovo\"\n",
    "            display_labels = threshold_name\n",
    "            \n",
    "        print(\"accuracy: \", accuracy_score(y_true, np.argmax(y_hat, axis=1)))\n",
    "        print(\"precision: \", precision_score(y_true, np.argmax(y_hat, axis=1), average=average))\n",
    "        print(\"recall: \", recall_score(y_true, np.argmax(y_hat, axis=1), average=average))\n",
    "        if binary:\n",
    "            print(\"roc auc: \", roc_auc_score(y_true, y_hat[:, 1], multi_class=multi_class))\n",
    "        else:\n",
    "            print(\"roc auc: \", roc_auc_score(y_true, y_hat, multi_class=multi_class))\n",
    "        print(\"f1: \", f1_score(y_true, np.argmax(y_hat, axis=1), average=average))\n",
    "        print(\"cohen kappa score: \", cohen_kappa_score(y_true, np.argmax(y_hat, axis=1)))\n",
    "        y_hat = np.argmax(y_hat, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_hat)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "    elif mode == \"regression\":\n",
    "        print(\"mse: \", mean_squared_error(y_true, y_hat))\n",
    "        print(\"mae: \", mean_absolute_error(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    clf = LogisticRegression(random_state=0, max_iter=10000, solver='saga')\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Logistic regression\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Random forest\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "\n",
    "    clf = SVC(random_state=0, probability=True)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"SVM\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "\n",
    "    clf = XGBClassifier(random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"XGBoost\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "elif mode == \"regression\":\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Linear regression\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)\n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Random forest\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)\n",
    "    \n",
    "    clf = SVR()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"SVM\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)\n",
    "    \n",
    "    clf = XGBRegressor(n_estimators=10, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"XGBoost\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5074a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e08237",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    x_img_train, y_img_train = x_img[[i > 80 for i in y_id]], y_img[[i > 80 for i in y_id]]\n",
    "    x_img_test, y_img_test = x_img[[i <= 80 for i in y_id]], y_img[[i <= 80 for i in y_id]]\n",
    "\n",
    "    predictions = np.argmax(clf.predict_proba(x_test), axis=1)\n",
    "    correct_index = predictions == y_test\n",
    "    for i, correct in enumerate(correct_index):\n",
    "        if correct:\n",
    "            correct_img = x_img_test[i]\n",
    "            correct_img = correct_img.astype(np.uint8)\n",
    "            cv2.putText(correct_img, str(y_test[i]), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.imshow(\"correct\", correct_img)\n",
    "            cv2.waitKey(500)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    wrong_index = predictions != y_test\n",
    "    for i, wrong in enumerate(wrong_index):\n",
    "        if wrong:\n",
    "            wrong_img = x_img_test[i]\n",
    "            wrong_img = wrong_img.astype(np.uint8)\n",
    "            cv2.putText(wrong_img, str(y_test[i]), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.imshow(\"wrong\", wrong_img)\n",
    "            cv2.waitKey(500)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
