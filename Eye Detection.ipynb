{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe992059",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c05fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(\"D:\", \"OneDrive_1_5-26-2022\", \"pid2625_charlesjohnson.xlsx\")\n",
    "data_path = os.path.join(\"D:\", \"OneDrive_1_5-26-2022\", \"pid2625\", \"pid2625\")\n",
    "metadata = pd.read_excel(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45734efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "\n",
    "for id in metadata[\"record\"].unique():\n",
    "    for eyeimage_i in metadata.loc[metadata['record'] == id][\"field_name\"]:\n",
    "        if eyeimage_i in [\"eyeimage1\", \"eyeimage2\"]:\n",
    "            file_name = metadata[(metadata[\"record\"] == id) & (metadata[\"field_name\"] == eyeimage_i)][\"stored_name\"].values[0]\n",
    "            #print(id, eyeimage_i, file_name)\n",
    "            image_path = os.path.join(data_path, file_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            #cv2.imshow(\"preview\", img)\n",
    "            #cv2.waitKey(1000)\n",
    "            #cv2.destroyAllWindows()\n",
    "            \n",
    "            #img = Image.open(image_path)\n",
    "            #img.show()\n",
    "            #imgArray = np.array(img)\n",
    "            if not images.get(id):\n",
    "                images[id] = {}\n",
    "            #images[id][eyeimage_i] = imgArray\n",
    "            images[id][eyeimage_i] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a46e68",
   "metadata": {},
   "source": [
    "# Eye detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b07cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(images[2].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17dc51",
   "metadata": {},
   "source": [
    "## Preliminary screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if not os.path.exists(\"./raw eyes images\"):\n",
    "    os.makedirs(\"./raw eyes images\")\n",
    "\n",
    "for id, image_id in images.items():\n",
    "    print(id)\n",
    "    \n",
    "    for i, image_i in image_id.items():\n",
    "        print(i)\n",
    "\n",
    "        #image_i = cv2.resize(image_i, (600, 800), interpolation = cv2.INTER_AREA)\n",
    "        #eyes = eye_cascade.detectMultiScale(image_i, scaleFactor = 1.001, minNeighbors = 10, minSize=[150, 150], maxSize=[500, 500])\n",
    "        eyes = eye_cascade.detectMultiScale(image_i, scaleFactor = 1.001, minNeighbors = 10, minSize=[600, 600], maxSize=[2000, 2000])\n",
    "        \n",
    "        # visualize the position of detected eyes\n",
    "        #for (x,y,w,h) in eyes:\n",
    "        #    cv2.rectangle(image_i,(x,y),(x+w,y+h),(0, 255, 0),5)\n",
    "        #cv2.imshow(\"Eyes Detected\", image_i)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "        # crop images of detected eyes\n",
    "        count = 0\n",
    "        for (x,y,w,h) in eyes:\n",
    "            count += 1\n",
    "            eyes_image_i = image_i[y:y+h, x:x+w,:]\n",
    "            #print(h, w)\n",
    "            #cv2.imshow(\"Eyes Detected\", eyes_image_i)\n",
    "            #cv2.waitKey(0)\n",
    "            if not os.path.exists(\"./raw eyes images/\" + str(id)):\n",
    "                os.makedirs(\"./raw eyes images/\" + str(id))\n",
    "            \n",
    "            cv2.imwrite(\"./raw eyes images/\" + str(id) + \"/\" + str(i) + \"_\" + str(count) + \".jpg\", eyes_image_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afae9f0",
   "metadata": {},
   "source": [
    "## Labeling dataset (eyelid vs non-eyelid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658aed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if not os.path.exists(\"./count images\"):\n",
    "    os.makedirs(\"./count images\")\n",
    "\n",
    "count = 0\n",
    "for id, image_id in images.items():\n",
    "    print(id)\n",
    "    \n",
    "    for i, image_i in image_id.items():\n",
    "        print(i)\n",
    "\n",
    "        #image_i = cv2.resize(image_i, (600, 800), interpolation = cv2.INTER_AREA)\n",
    "        #eyes = eye_cascade.detectMultiScale(image_i, scaleFactor = 1.001, minNeighbors = 10, minSize=[150, 150], maxSize=[500, 500])\n",
    "        eyes = eye_cascade.detectMultiScale(image_i, scaleFactor = 1.001, minNeighbors = 10, minSize=[600, 600], maxSize=[2000, 2000])\n",
    "        \n",
    "        # visualize the position of detected eyes\n",
    "        #for (x,y,w,h) in eyes:\n",
    "        #    cv2.rectangle(image_i,(x,y),(x+w,y+h),(0, 255, 0),5)\n",
    "        #cv2.imshow(\"Eyes Detected\", image_i)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "        # crop images of detected eyes\n",
    "        for (x,y,w,h) in eyes:\n",
    "            count += 1\n",
    "            eyes_image_i = image_i[y:y+h, x:x+w,:]\n",
    "            #print(h, w)\n",
    "            #cv2.imshow(\"Eyes Detected\", eyes_image_i)\n",
    "            #cv2.waitKey(0)\n",
    "            if not os.path.exists(\"./count images/\" + str(id)):\n",
    "                os.makedirs(\"./count images/\" + str(id))\n",
    "            \n",
    "            cv2.imwrite(\"./count images/\" + str(id) + \"/\" + str(id) + \"_\" + str(count) + \".jpg\", eyes_image_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad82850",
   "metadata": {},
   "source": [
    "# Eyelid- and non-eyelid images classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyelid_images_path = os.path.join(\"eyelid images\")\n",
    "\n",
    "seed_list = [123, 124, 125, 126, 127]\n",
    "seed_num = 0\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "  eyelid_images_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=seed_list[seed_num],\n",
    "  image_size=(224, 224),\n",
    "  batch_size=32)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  eyelid_images_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=seed_list[seed_num],\n",
    "  image_size=(224, 224),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0820c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a18f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # Add the preprocessing layers you created earlier.\n",
    "  tf.keras.layers.Resizing(224, 224),\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "p_tb = TensorBoard(log_dir='./logs/pretraining')\n",
    "f_tb = TensorBoard(log_dir='./logs/finetuning')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=[es, p_tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d165c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in base_model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=[es, f_tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in val_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(str(labels[i].numpy()))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a72312",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in val_ds.take(1):\n",
    "  print(labels)\n",
    "  y_hat = np.squeeze(model.predict(images) >= 0.5)\n",
    "  print(y_hat)\n",
    "  print(\"wrong: \", np.sum(labels != y_hat), \"/\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d214d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./models/\" + str(seed_list[seed_num]) + \"_\" + str(0.9413) + \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559df60",
   "metadata": {},
   "source": [
    "# Eyelid Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f38bf4",
   "metadata": {},
   "source": [
    "## Finding potential eyelid images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b322124",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if not os.path.exists(\"./potential eyes images\"):\n",
    "    os.makedirs(\"./potential eyes images\")\n",
    "\n",
    "for id, image_id in images.items():\n",
    "    print(id)\n",
    "    \n",
    "    for i, image_i in image_id.items():\n",
    "        print(i)\n",
    "\n",
    "        #image_i = cv2.resize(image_i, (600, 800), interpolation = cv2.INTER_AREA)\n",
    "        #eyes = eye_cascade.detectMultiScale(image_i, scaleFactor = 1.001, minNeighbors = 10, minSize=[150, 150], maxSize=[500, 500])\n",
    "        eyes = eye_cascade.detectMultiScale(image_i, scaleFactor = 1.0001, minNeighbors = 1, minSize=[600, 600], maxSize=[2000, 2000])\n",
    "        \n",
    "        # visualize the position of detected eyes\n",
    "        #for (x,y,w,h) in eyes:\n",
    "        #    cv2.rectangle(image_i,(x,y),(x+w,y+h),(0, 255, 0),5)\n",
    "        #cv2.imshow(\"Eyes Detected\", image_i)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "        # crop images of detected eyes\n",
    "        count = 0\n",
    "        for (x,y,w,h) in eyes:\n",
    "            count += 1\n",
    "            eyes_image_i = image_i[y:y+h, x:x+w,:]\n",
    "            #print(h, w)\n",
    "            #cv2.imshow(\"Eyes Detected\", eyes_image_i)\n",
    "            #cv2.waitKey(0)\n",
    "            if not os.path.exists(\"./potential eyes images/\" + str(id)):\n",
    "                os.makedirs(\"./potential eyes images/\" + str(id))\n",
    "            \n",
    "            cv2.imwrite(\"./potential eyes images/\" + str(id) + \"/\" + str(i) + \"_\" + str(count) + \".jpg\", eyes_image_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  # Add the preprocessing layers you created earlier.\n",
    "  tf.keras.layers.Resizing(224, 224),\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  model\n",
    "])\n",
    "\n",
    "model.load_weights(\"./models/123_0.9413/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./detected eyes images\"):\n",
    "    os.makedirs(\"./detected eyes images\")\n",
    "    \n",
    "for folder in os.listdir(\"./potential eyes images\"):\n",
    "    for image in os.listdir(os.path.join(\"./potential eyes images\", folder)):\n",
    "        #print(image)\n",
    "        img = cv2.imread(os.path.join(\"./potential eyes images\", folder, image))\n",
    "        #cv2.imshow(\"Eye detected\", img)\n",
    "        #cv2.waitKey(0)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        y_hat = model.predict(img, verbose=0)\n",
    "        #print(y_hat)\n",
    "        \n",
    "        if y_hat < 0.5:\n",
    "            if not os.path.exists(os.path.join(\"./detected eyes images\", folder)):\n",
    "                os.makedirs(os.path.join(\"./detected eyes images\", folder))\n",
    "                \n",
    "            cv2.imwrite(os.path.join(\"./detected eyes images\", folder, image), img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7909b",
   "metadata": {},
   "source": [
    "# Anemia prediction (Classification & Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"classification\"\n",
    "#mode = \"regression\"\n",
    "binary = False\n",
    "threshold = [7.0, 10.0, 12.5]\n",
    "threshold_name = [\"severely anemic\", \"moderately anemic\", \"mildly anemic\", \"non-anemic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209f854",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = os.path.join(\"D:\", \"OneDrive_1_5-26-2022\", \"PredictingAnemia_DATA_2022-06-05_0643.csv\")\n",
    "label = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[\"hgb\"] = pd.to_numeric(label[\"hgb\"], errors=\"coerce\")\n",
    "drop_index = np.where(pd.isnull(label[\"hgb\"]))\n",
    "print(\"drop (contains string or null): \", drop_index[0])\n",
    "label = label.drop(drop_index[0])\n",
    "print(\"mean:\", label[\"hgb\"].mean(), \"std:\", label[\"hgb\"].std())\n",
    "print(\"anemia mean: \", label[\"hgb\"][label[\"hgb\"] < 12.5].mean())\n",
    "print(\"non-anemia mean: \", label[\"hgb\"][label[\"hgb\"] >= 12.5].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_label(label_i, threshold):\n",
    "    label = -1\n",
    "    for i, threshold_i in enumerate(threshold):\n",
    "        if label_i < threshold_i:\n",
    "            label = i\n",
    "            break\n",
    "    if label == -1:\n",
    "        label = len(threshold)\n",
    "    \n",
    "    #print(label, label_i)\n",
    "    \n",
    "    return label\n",
    "\n",
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        y = (label[\"hgb\"] < 12.5).astype(int)\n",
    "    else:\n",
    "        y = np.array([multi_class_label(label_i, threshold) for label_i in label[\"hgb\"]], dtype=np.uint8)\n",
    "        y = pd.Series(data=y, index=label[\"hgb\"].index)\n",
    "elif mode == \"regression\":\n",
    "    y = label[\"hgb\"]\n",
    "print(y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc324d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_available = [] \n",
    "\n",
    "for folder in os.listdir(\"./detected eyes images\"):\n",
    "    if int(folder)-1 in y.index:\n",
    "        y_available.append(int(folder))\n",
    "        \n",
    "print(\"not available id: \")\n",
    "not_available_id = []\n",
    "for i in range(1, 693):\n",
    "    if i not in y_available:\n",
    "        not_available_id.append(i)\n",
    "print(not_available_id)\n",
    "print(\"num: \", len(not_available_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b3320",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = []\n",
    "y_img = []\n",
    "y_id = []\n",
    "\n",
    "for id in y_available:\n",
    "    for image in os.listdir(os.path.join(\"./detected eyes images\", str(id))):\n",
    "        #print(id, image)\n",
    "        img = cv2.imread(os.path.join(\"./detected eyes images\", str(id), image))\n",
    "        #print(img.shape)\n",
    "        x_img.append(tf.image.resize(img, (224, 224)))\n",
    "        y_img.append(y[id-1])\n",
    "        y_id.append(id)\n",
    "        \n",
    "x_img = np.array(x_img, dtype=np.uint8)\n",
    "y_img = np.array(y_img)\n",
    "print(x_img.shape, y_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552220fd",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded10293",
   "metadata": {},
   "source": [
    "### Changing the contrast and brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2964c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookUpTable = np.empty((1,256), np.uint8)\n",
    "gamma = 1.3\n",
    "for i in range(256):\n",
    "    lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "\n",
    "def adjust_brightness(img, lookUpTable, alpha=1.3, beta=40):\n",
    "    new_image = np.zeros(img.shape, img.dtype)\n",
    "    \n",
    "    #for y in range(img.shape[0]):\n",
    "    #    for x in range(img.shape[1]):\n",
    "    #        for c in range(img.shape[2]):\n",
    "    #            new_image[y,x,c] = np.clip(alpha*img[y,x,c] + beta, 0, 255)\n",
    "\n",
    "    new_image = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "                \n",
    "    res = cv2.LUT(new_image, lookUpTable)\n",
    "                \n",
    "    return res\n",
    "\n",
    "# x_brightness = np.array([adjust_brightness(xi, lookUpTable) for xi in x_img], dtype=np.uint8)\n",
    "# print(x_brightness.shape)\n",
    "\n",
    "# x_preprocessed = np.array(x_brightness, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2141124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = x_img[20]\n",
    "# result = x_brightness[20]\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "# cv2.imshow('result', result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5012f0",
   "metadata": {},
   "source": [
    "### Clustering filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_filter(img, n_clusters=5):\n",
    "    original_shape = img.shape\n",
    "    img = img.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(img)\n",
    "\n",
    "    labels=kmeans.labels_\n",
    "    #print(labels)\n",
    "    labels=list(labels)\n",
    "\n",
    "    centroid=kmeans.cluster_centers_\n",
    "    #print(centroid)\n",
    "\n",
    "    percent=[]\n",
    "    for i in range(len(centroid)):\n",
    "      j=labels.count(i)\n",
    "      j=j/(len(labels))\n",
    "      percent.append(j)\n",
    "    #print(percent)\n",
    "\n",
    "    # bgr to rgb\n",
    "    #plt.pie(percent,colors=np.array(centroid[:, [2, 1, 0]]/255),labels=np.arange(len(centroid)))\n",
    "    #plt.show()\n",
    "\n",
    "    sorted_percent = sorted(percent)\n",
    "    remove_index = [percent_i in [sorted_percent[0], sorted_percent[1]] for percent_i in percent]\n",
    "    #print(remove_index)\n",
    "\n",
    "    result = np.array(img, copy=True)\n",
    "    for i, remove in enumerate(remove_index):\n",
    "        if remove:\n",
    "            result[labels==np.array(i)] = centroid[i]\n",
    "    result = result.reshape(original_shape)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# x_cluster = np.array([clustering_filter(xi) for xi in x_img], dtype=np.uint8)\n",
    "# print(x_cluster.shape)\n",
    "\n",
    "# x_preprocessed = np.array(x_cluster, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = x_img[321]\n",
    "# result = x_cluster[321]\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "# cv2.imshow('result', result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9272ec",
   "metadata": {},
   "source": [
    "### HSV filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_sum = []\n",
    "\n",
    "def hsv_filter(img, init_value=100, end_value=0, average_value=20000, adaptive=False):\n",
    "    mask_value = 0\n",
    "    sv_value = init_value\n",
    "    \n",
    "    if adaptive:\n",
    "        while mask_value <= average_value and sv_value >= end_value:\n",
    "            # Threshold of blue in HSV space\n",
    "            lower_red = np.array([0,sv_value,sv_value])\n",
    "            upper_red = np.array([10,255,255])\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            # preparing the mask to overlay\n",
    "            mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "            mask_value = np.sum(mask/255)\n",
    "            sv_value -= 1\n",
    "    else:\n",
    "        lower_red = np.array([0,sv_value,sv_value])\n",
    "        upper_red = np.array([10,255,255])\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        # preparing the mask to overlay\n",
    "        mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask_value = np.sum(mask/255)\n",
    "        \n",
    "    dummy_sum.append(mask_value)\n",
    "\n",
    "\n",
    "    # The black region in the mask has the value of 0,\n",
    "    # so when multiplied with original image removes all non-blue regions\n",
    "    result = cv2.bitwise_and(img, img, mask = mask)\n",
    "    \n",
    "    return result\n",
    "\n",
    "x_hsv = np.array([hsv_filter(xi) for xi in x_img], dtype=np.uint8)\n",
    "print(x_hsv.shape)\n",
    "\n",
    "print(np.mean(np.array(dummy_sum), axis=0))\n",
    "\n",
    "x_preprocessed = np.array(x_hsv, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = x_img[60]\n",
    "# result = x_hsv[60]\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "# cv2.imshow('result', result)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ac2cb",
   "metadata": {},
   "source": [
    "### Histrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c98dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue, Green, Red and A (Transparency)\n",
    "def red_histogram(img):\n",
    "    return np.histogram(img[:, :, 2].flatten(), range(257))[0]\n",
    "\n",
    "x_hist = np.array([red_histogram(xi) for xi in x_preprocessed])\n",
    "print(x_hist.shape)\n",
    "\n",
    "x_final = x_hist\n",
    "y_final = y_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380753a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(256)[1:] - 0.5, x_hist[0][1:], width=1, edgecolor='none')\n",
    "plt.xlim([-0.5, 255.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca45762",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1458a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by id\n",
    "x_train, y_train = x_final[[i > 80 for i in y_id]], y_final[[i > 80 for i in y_id]]\n",
    "x_test, y_test = x_final[[i <= 80 for i in y_id]], y_final[[i <= 80 for i in y_id]]\n",
    "\n",
    "#x_train, y_train = x_final[[i < 620 for i in y_id]], y_final[[i < 620 for i in y_id]]\n",
    "#x_test, y_test = x_final[[i >= 620 for i in y_id]], y_final[[i >= 620 for i in y_id]]\n",
    "\n",
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        print(\"train: (0)\", np.sum(y_train==0), \"(1)\", np.sum(y_train==1))\n",
    "        print(\"test: (0)\", np.sum(y_test==0), \"(1)\", np.sum(y_test==1))\n",
    "    else:\n",
    "        for i in range(len(threshold)+1):\n",
    "            print(i)\n",
    "            print(\"train:\", np.sum(y_train==i), \" test:\", np.sum(y_test==i))\n",
    "elif mode == \"regression\":\n",
    "    print(np.mean(y_train))\n",
    "    print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be455b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train==0].mean(axis=0)[1:], label='non-anemia')\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train==1].mean(axis=0)[1:], label='anemia')\n",
    "    else:\n",
    "        for i in range(len(threshold)+1):\n",
    "            plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train==i].mean(axis=0)[1:], label=threshold_name[i])\n",
    "elif mode == \"regression\":\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train>=12.5].mean(axis=0)[1:], label='non-anemia')\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_train[y_train<12.5].mean(axis=0)[1:], label='anemia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8507a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    if binary:\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test==0].mean(axis=0)[1:], label='non-anemia')\n",
    "        plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test==1].mean(axis=0)[1:], label='anemia')\n",
    "    else:\n",
    "        for i in range(len(threshold)+1):\n",
    "            plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test==i].mean(axis=0)[1:], label=threshold_name[i])\n",
    "elif mode == \"regression\":\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test>=12.5].mean(axis=0)[1:], label='non-anemia')\n",
    "    plt.plot(np.arange(256)[1:] - 0.5, x_test[y_test<12.5].mean(axis=0)[1:], label='anemia')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ceb83",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860501cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, y_hat, mode, binary):\n",
    "    if mode == \"classification\":\n",
    "        if binary:\n",
    "            average = \"binary\"\n",
    "            multi_class = \"raise\"\n",
    "            display_labels = [\"non-anemia\", \"anemia\"]\n",
    "        else:\n",
    "            average = \"macro\"\n",
    "            multi_class = \"ovo\"\n",
    "            display_labels = threshold_name\n",
    "            \n",
    "        print(\"accuracy: \", accuracy_score(y_true, np.argmax(y_hat, axis=1)))\n",
    "        print(\"precision: \", precision_score(y_true, np.argmax(y_hat, axis=1), average=average))\n",
    "        print(\"recall: \", recall_score(y_true, np.argmax(y_hat, axis=1), average=average))\n",
    "        if binary:\n",
    "            print(\"roc auc: \", roc_auc_score(y_true, y_hat[:, 1], multi_class=multi_class))\n",
    "        else:\n",
    "            print(\"roc auc: \", roc_auc_score(y_true, y_hat, multi_class=multi_class))\n",
    "        print(\"f1: \", f1_score(y_true, np.argmax(y_hat, axis=1), average=average))\n",
    "        print(\"cohen kappa score: \", cohen_kappa_score(y_true, np.argmax(y_hat, axis=1)))\n",
    "        y_hat = np.argmax(y_hat, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_hat)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "    elif mode == \"regression\":\n",
    "        print(\"mse: \", mean_squared_error(y_true, y_hat))\n",
    "        print(\"mae: \", mean_absolute_error(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    clf = LogisticRegression(random_state=0, max_iter=10000, solver='saga')\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Logistic regression\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Random forest\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "\n",
    "    clf = SVC(random_state=0, probability=True)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"SVM\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "\n",
    "    clf = XGBClassifier(random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"XGBoost\")\n",
    "    print_results(y_test, clf.predict_proba(x_test), mode, binary)\n",
    "elif mode == \"regression\":\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Linear regression\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)\n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Random forest\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)\n",
    "    \n",
    "    clf = SVR()\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"SVM\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)\n",
    "    \n",
    "    clf = XGBRegressor(n_estimators=10, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"XGBoost\")\n",
    "    print_results(y_test, clf.predict(x_test), mode, binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5074a",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e08237",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    x_img_train, y_img_train = x_img[[i > 80 for i in y_id]], y_img[[i > 80 for i in y_id]]\n",
    "    x_img_test, y_img_test = x_img[[i <= 80 for i in y_id]], y_img[[i <= 80 for i in y_id]]\n",
    "\n",
    "    predictions = np.argmax(clf.predict_proba(x_test), axis=1)\n",
    "    correct_index = predictions == y_test\n",
    "    for i, correct in enumerate(correct_index):\n",
    "        if correct:\n",
    "            correct_img = x_img_test[i]\n",
    "            correct_img = correct_img.astype(np.uint8)\n",
    "            cv2.putText(correct_img, str(y_test[i]), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.imshow(\"correct\", correct_img)\n",
    "            cv2.waitKey(500)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"classification\":\n",
    "    wrong_index = predictions != y_test\n",
    "    for i, wrong in enumerate(wrong_index):\n",
    "        if wrong:\n",
    "            wrong_img = x_img_test[i]\n",
    "            wrong_img = wrong_img.astype(np.uint8)\n",
    "            cv2.putText(wrong_img, str(y_test[i]), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.imshow(\"wrong\", wrong_img)\n",
    "            cv2.waitKey(500)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
